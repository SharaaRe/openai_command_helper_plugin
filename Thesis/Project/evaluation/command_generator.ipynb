{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas\n",
    "import openai \n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import json\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import openai\n",
    "from openai import AsyncOpenAI as OpenAI\n",
    "\n",
    "\n",
    "         \n",
    "\n",
    "        \n",
    "# Project/prompts/5.txt\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openai_key():\n",
    "       # Specify the path to your .env file\n",
    "       env_file_path = '../.env'  # Update this with the correct path\n",
    "        # Load the environment variables from the .env file\n",
    "       load_dotenv(env_file_path)\n",
    "        # Access your API key by referencing the environment variable\n",
    "       api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "       print(api_key)\n",
    "       openai.api_key = api_key\n",
    "       client = OpenAI()\n",
    "       return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion async \n",
    "\n",
    "async def get_completion(client, model, user_instruction, prompt):\n",
    "        print('th')\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt.format(user_instruction=user_instruction)}]\n",
    "        wait_time = 1\n",
    "\n",
    "        try:\n",
    "                response =  await client.chat.completions.create(\n",
    "                                        model=model,\n",
    "                                        messages=messages,\n",
    "                                        temperature=0, # this is the degree of randomness of the model's output\n",
    "                                )\n",
    "                return {user_instruction: json.loads(response.choices[0].message.content)}\n",
    "                \n",
    "        except openai.APIError as e:\n",
    "                #Handle API error here, e.g. retry or log\n",
    "                print(f\"OpenAI API returned an API Error: {e}\")\n",
    "                return user_instruction, 'APIError'\n",
    "        except openai.APIConnectionError as e:\n",
    "                #Handle connection error here\n",
    "                print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "                return user_instruction, 'APIConnectionError'\n",
    "\n",
    "        except openai.RateLimitError as e:\n",
    "                #Handle rate limit error (we recommend using exponential backoff)\n",
    "                print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "                return user_instruction, 'RateLimitError'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_prompt(prompt_file):\n",
    "\n",
    "        with open(prompt_file, 'r') as file:\n",
    "                prompt = file.read().replace('\\n', '')\n",
    "                return prompt\n",
    "        \n",
    "\n",
    "\n",
    "def load_instructions(instruction_file):\n",
    "      with open(instruction_file) as f:\n",
    "        data = json.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_get_gpt_response(client, model, data, prompt):\n",
    "        commands = []\n",
    "        tasks = []\n",
    "        for instruction in data:\n",
    "\n",
    "                task = asyncio.create_task(get_completion(client, model, instruction, prompt))\n",
    "                # time.sleep(1)\n",
    "                tasks.append(task)\n",
    "                print('there')  \n",
    "        \n",
    "        commands = await asyncio.gather(*tasks)\n",
    "\n",
    "        return commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "async def run_script(client, model, prompt_file, instructions_file):\n",
    "        results = []\n",
    "\n",
    "        # try:\n",
    "        prompt = load_prompt(prompt_file)\n",
    "        print(f\"Prompt loaded! '{prompt}'\")\n",
    "        instructions = load_instructions(instructions_file)\n",
    "        print(f\"{len(instructions)} instructions loaded\")\n",
    "        # print(instructions)\n",
    "        chunk_size = 10\n",
    "        instruction_chunks = [instructions[i:i + chunk_size] for i in range(0, len(instructions), chunk_size)]\n",
    "        for i, chunk in enumerate(instruction_chunks[5:]): \n",
    "                print(f'Chunk number {i}')\n",
    "                responses = await async_get_gpt_response(client,model, chunk, prompt)\n",
    "                print('here')\n",
    "                print(responses)\n",
    "                results += responses\n",
    "\n",
    "        # except Exception as e:\n",
    "        #        print('failed!', e)\n",
    "\n",
    "        # finally:\n",
    "        output_path = f'./{prompt_file[:-4]}_{model}_responses.json'\n",
    "        print(output_path)\n",
    "        with open(output_path, 'w') as f:\n",
    "                print(f)\n",
    "                # results = dict(ChainMap(*results))\n",
    "                json.dump(results, f)\n",
    "                                # res = json.l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = load_openai_key()\n",
    "# asyncio.run(run_script(prompt_file, instructions_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../prompts/5.txt ./samples/test_instructions_small.json\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt-3.5-turbo'\n",
    "# model = 'gpt-4-turbo-preview'\n",
    "# model = 'gpt-4'\n",
    "prompt_file = \"../prompts/5.txt\"\n",
    "instructions_file = \"./samples/test_instructions_small.json\"\n",
    "print(prompt_file, instructions_file)\n",
    "# asyncio.run_coroutine_threadsafe(run_script(client, model, prompt_file, instructions_file), loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_file = \"../prompts/6.txt\"\n",
    "instructions_file = \"./samples/test_instructions_small.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x113cbce90 state=pending>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt loaded! 'You are an expert rhino3d designer who can work with rhino3d api,the user will give you instructions about an action in rhino and you should give a list of 'RhinoScript' forrunning in RhinoCommon framework 'RunScript' method, list the commands in a json.Take these steps to make sure you generate the proper script.1. Find the steps needed for the instruction to be executed.2. Find the proper command for each step3. Make sure you are using the correct parameters and their orders for each command. 4. Genereate the command for each step and fill in the unknown values for parameters with default values.5. structure the commands in a json format.The following examples are here to help you with the structure of the output: 1. user instruction: \"please create a sphere\" >> output: \"{{\"RhinoScript\" [\"_Sphere 0,0,0 1\"]}}\"2. user instruction: \"I want an array of the last object created\" >> output: \"{{\"RhinoScript\": [ \"_-SelLast\", \"_ArrayLinear _Count=5 _Direction=1,0,0 _Distance=10 _DeleteInput=No\"]}}\"3. user instruction: \"Create an ellipse with a major axis of 15 units and a minor axis of 10 units.\" >> output: \"{{\"RhinoScript\": [\"_Ellipse 0,0,0 0,15,0 10,0,0\"]}}\"The output should follow the structure above.This is user's request: << {user_instruction} >>Please make sure it is a valid syntax and works if I feed it to the rhino command line!'\n",
      "10 instructions loaded\n",
      "./../prompts/6_gpt-3.5-turbo_responses.json\n",
      "<_io.TextIOWrapper name='./../prompts/6_gpt-3.5-turbo_responses.json' mode='w' encoding='utf-8'>\n"
     ]
    }
   ],
   "source": [
    "asyncio.run_coroutine_threadsafe(run_script(client, model, prompt_file, instructions_file), loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
